{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "# from PIL import Image\n",
    "import pydicom\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn\n",
    "import torchvision.models as models  \n",
    "import matplotlib.pyplot as plt\n",
    "import pre_function as pre\n",
    "import SimpleITK as sitk\n",
    "# import nibabel as nib\n",
    "import joblib\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "summaryWriter = SummaryWriter(\"./logs/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './vali'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normMeanPET = 516.5095631343381\n",
    "normStdPET = 1782.5365338158515\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "normalize_pet = transforms.Normalize(\n",
    "   mean=normMeanPET,\n",
    "   std=normStdPET\n",
    ")\n",
    "\n",
    "transform_pet = transforms.Compose([transforms.ToTensor(), normalize_pet])  \n",
    "transform_mask = transforms.Compose([transforms.ToTensor()])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PLEDataset(Dataset):\n",
    "    def __init__(self, data_list,shape,transform_pet,transform_mask):\n",
    "    # def __init__(self, img_paths, img_labels):\n",
    "        self.list = data_list\n",
    "        # self.labels = labels\n",
    "        self.shape = shape\n",
    "        # self.size_of_images = size_of_images\n",
    "        self.transform_mask = transform_mask\n",
    "        self.transform_pet = transform_pet\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list)\n",
    "    def __getitem__(self, index):\n",
    "        # img = cv2.resize(self.list[index],self.size_of_images)\n",
    "        path = self.list[index]\n",
    "        data = joblib.load(path)\n",
    "        pet = data[0]\n",
    "        mask = data[1]\n",
    "        num_layer = pet.shape[0]\n",
    "        if num_layer>200:\n",
    "            pet = pet[num_layer-178:num_layer-44,:,:]\n",
    "            mask = mask[num_layer-178:num_layer-44,:,:]\n",
    "        # shape = [134,100,100]\n",
    "        p1 = []\n",
    "        p2 = []\n",
    "        for i in range(3):\n",
    "            if pet.shape[i] < shape[i]:\n",
    "                a = int((shape[i]-pet.shape[i])/2)\n",
    "                p1.append(a)\n",
    "                p2.append(shape[i] - pet.shape[i] - a)\n",
    "            else:\n",
    "                p1.append(0)\n",
    "                p2.append(0)\n",
    "        img_pet = np.pad(pet,pad_width=((p1[0], p2[0]),\n",
    "                                        (p1[1], p2[1]),\n",
    "                                        (p1[2],p2[2])),mode=\"constant\",constant_values=(0,0))\n",
    "        img_mask = np.pad(mask,pad_width=((p1[0], p2[0]),\n",
    "                                        (p1[1], p2[1]),\n",
    "                                        (p1[2],p2[2])),mode=\"constant\",constant_values=(0,0))\n",
    "        c1 = abs(int((img_pet.shape[0]-shape[0])/2))\n",
    "        c2 = abs(int((img_pet.shape[0]+shape[0])/2))\n",
    "        h1 = abs(int((img_pet.shape[1]-shape[1])/2))\n",
    "        h2 = abs(int((img_pet.shape[1]+shape[1])/2))\n",
    "        w1 = abs(int((img_pet.shape[2]-shape[2])/2))\n",
    "        w2 = abs(int((img_pet.shape[2]+shape[2])/2))\n",
    "        img_pet = img_pet[c1:c2,h1:h2,w1:w2]\n",
    "        img_mask = img_mask[c1:c2,h1:h2,w1:w2]\n",
    "\n",
    "        img_pet = img_pet.astype(np.float32)\n",
    "        img_mask = img_mask.astype(np.float32)\n",
    "        # img_pet = torch.tensor(img_pet)\n",
    "        TENSOR_pet = self.transform_pet(img_pet)\n",
    "        TENSOR_mask = self.transform_mask(img_mask)\n",
    "        # TENSOR_pet = torch.unsqueeze(TENSOR_pet,dim=0)\n",
    "        # TENSOR_mask = torch.unsqueeze(TENSOR_mask,dim=0)\n",
    "        # TENSOR_pet = torch.tensor(img_pet)\n",
    "        # TENSOR_mask = torch.tensor(img_mask)\n",
    "        # label = self.labels[index]\n",
    "        return TENSOR_pet, TENSOR_mask\n",
    "shape = [128,128,128]\n",
    "test_set = PLEDataset(path,shape,transform_pet,transform_mask)\n",
    "test_loader = torch.utils.data.DataLoader(test_set,batch_size=2,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import monai\n",
    "model = monai.networks.nets.UNet(spatial_dims=3, in_channels=1, out_channels=2,channels=(32,64,128,256),strides=(2,2,2)).to(device)\n",
    "# model = monai.networks.nets.BasicUNet().to(device)  # out of memory\n",
    "# model = monai.networks.nets.AttentionUnet(spatial_dims=3, in_channels=1, out_channels=2, channels=(32,64,128,256),strides=(2,2,2)).to(device)  # out of memory\n",
    "# model = monai.networks.nets.SwinUNETR(img_size=(128,128,128), in_channels=1, out_channels=2).to(device) # out of memory\n",
    "pretrain_path = './output/unet_pre60_meandice/weights/model120.pth'\n",
    "no_cuda = False\n",
    "gpu_id = [0]\n",
    "if not no_cuda:\n",
    "    if len(gpu_id) > 1:\n",
    "        model = model.cuda()\n",
    "        model = nn.DataParallel(model, device_ids=gpu_id)\n",
    "        net_dict = model.state_dict()\n",
    "    else:\n",
    "        import os\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(gpu_id[0])\n",
    "        model = model.cuda()\n",
    "        model = nn.DataParallel(model, device_ids=None)\n",
    "        net_dict = model.state_dict()\n",
    "else:\n",
    "    net_dict = model.state_dict()\n",
    "\n",
    "print('loading pretrained model {}'.format(pretrain_path))\n",
    "pretrain = torch.load(pretrain_path)\n",
    "# pretrain_dict = {k: v for k, v in pretrain['state_dict'].items() if k in net_dict.keys()}\n",
    "pretrain_dict = {k: v for k, v in pretrain.items() if k in net_dict.keys()}\n",
    "net_dict.update(pretrain_dict) \n",
    "model.load_state_dict(net_dict) \n",
    "print(\"-------- pre-train model load successfully --------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import logger, weights_init, metrics, common, loss\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "# criterion = torch.nn.BCELoss().to(device)\n",
    "criterion = loss.DiceLoss().to(device)\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.99)\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "from sklearn.metrics import auc\n",
    "for epoch in range(num_epochs):\n",
    "    start = time.time()\n",
    "    per_epoch_loss = 0\n",
    "    score_list = [] \n",
    "    label_list = []\n",
    "    per_epoch_metrics = 0\n",
    "    \n",
    "    val_per_epoch_loss = 0\n",
    "    val_per_epoch_metrics = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x,label in tqdm(test_loader):\n",
    "            x = x.float() \n",
    "            x = x.to(device)\n",
    "            label = label.long()\n",
    "            label = common.to_one_hot_3d(label, 2)\n",
    "            label = label.to(device)\n",
    "            #label_n = label.cpu().numpy()\n",
    "            \n",
    "            # val_label_list.extend(label.cpu().numpy())\n",
    "            x=torch.unsqueeze(x, dim=1)\n",
    "           \n",
    "            # Forward pass\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, label)\n",
    "            # print(loss)\n",
    "            val_per_epoch_loss += loss.item()\n",
    "            # metrics = monai.metrics.compute_iou(logits,label,include_background=False)[0]\n",
    "            score, not_nans = monai.metrics.DiceHelper(include_background=False, sigmoid=True, softmax=True)(logits,label)\n",
    "            val_per_epoch_metrics += score.item()\n",
    "        # print(\"val Epoch: {}\\t Acc: {:.6f}\".format(epoch,val_num_correct/len(loader.dataset)))\n",
    "        \n",
    "        # summaryWriter.add_scalars('acc', {\"val_acc\":val_num_correct/len(loader.dataset)}, epoch)\n",
    "        # summaryWriter.add_scalars('time', {\"time\":(time.time() - start)}, epoch)\n",
    "\n",
    "            # pro_list = prob_out.detach().cpu().numpy()\n",
    "            \n",
    "            #print(pro_list)\n",
    "            # for i in range(pro_list.shape[0]):\n",
    "            #     if (pro_list[i] > 0.5) == label.cpu().numpy()[i]:\n",
    "            #         val_num_correct += 1\n",
    "            \n",
    "            # val_score_list.extend(pro_list)\n",
    "            \n",
    "\n",
    "        # score_array = np.array(val_score_list)\n",
    "        # label_array = np.array(val_label_list)\n",
    "        # fpr_keras_1, tpr_keras_1, thresholds_keras_1 = roc_curve(label_array, score_array)\n",
    "        # auc_keras_1 = auc(fpr_keras_1,tpr_keras_1)        \n",
    "\n",
    "        # print(\"val Epoch: {}\\t Acc: {:.6f} AUC: {:.6f} \".format(epoch,val_num_correct/len(test_loader.dataset),auc_keras_1))\n",
    "        # summaryWriter.add_scalars('acc', {\"val_acc\":val_num_correct/len(test_loader.dataset)}, epoch)\n",
    "        # summaryWriter.add_scalars('auc', {\"val_auc\":auc_keras_1}, epoch)\n",
    "        # summaryWriter.add_scalars('time', {\"time\":(time.time() - start)}, epoch)\n",
    "        \n",
    "    scheduler.step()\n",
    "\n",
    "    #filepath = \"./weights\"\n",
    "    #folder = os.path.exists(filepath)\n",
    "    #if not folder:\n",
    "    #    os.makedirs(filepath)\n",
    "    #path = './weights/model' + str(epoch) + '.pth'\n",
    "    #torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = logits.cpu().numpy()\n",
    "target = label.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output1 = output[0,0,:,:,:]\n",
    "output2 = output[0,1,:,:,:]\n",
    "target1 = target[0,0,:,:,:]\n",
    "target2 = target[0,1,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = sitk.GetImageFromArray(output1)\n",
    "img2 = sitk.GetImageFromArray(output2)\n",
    "img3 = sitk.GetImageFromArray(target1)\n",
    "img4 = sitk.GetImageFromArray(target2)\n",
    "sitk.WriteImage(img1, './output1.nii.gz')\n",
    "sitk.WriteImage(img2, './output2.nii.gz')\n",
    "sitk.WriteImage(img3, './target1.nii.gz')\n",
    "sitk.WriteImage(img4, './target2.nii.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4c8ad89b3872937943a9c81c0f4e530de6ed8aab4b8488e0ec1cc457090dfae"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
