{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "# from PIL import Image\n",
    "import pydicom\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn\n",
    "import torchvision.models as models  \n",
    "import matplotlib.pyplot as plt\n",
    "import pre_function as pre\n",
    "import SimpleITK as sitk\n",
    "# import nibabel as nib\n",
    "import joblib\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "summaryWriter = SummaryWriter(\"./logs/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path0 = './segdl/0'\n",
    "path1 = './segdl/1'\n",
    "path_list0 = os.listdir(path0)\n",
    "path_list1 = os.listdir(path1)\n",
    "path_name0 = [os.path.join(path0,i) for i in path_list0]\n",
    "path_name1 = [os.path.join(path1,i) for i in path_list1]\n",
    "path = path_name0 + path_name1\n",
    "path = [os.path.join(i,\"ct_mask_new.pkl\") for i in path]\n",
    "\n",
    "len(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_mask, stdevs_mask,means_pet, stdevs_pet = 0,0,0,0\n",
    "num_imgs = 0\n",
    "\n",
    "for item in path:\n",
    "    num_imgs += 1\n",
    "    data = joblib.load(item)\n",
    "    item_pet = data[1]\n",
    "    pet_pixel = item_pet.astype(np.float32)\n",
    "    means_pet += pet_pixel.mean()\n",
    "    stdevs_pet += pet_pixel.std()\n",
    "\n",
    "normMeanPET = means_pet / num_imgs\n",
    "normStdPET = stdevs_pet / num_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "normalize_pet = transforms.Normalize(\n",
    "   mean=normMeanPET,\n",
    "   std=normStdPET\n",
    ")\n",
    "\n",
    "transform_pet = transforms.Compose([transforms.ToTensor(), normalize_pet])  \n",
    "transform_mask = transforms.Compose([transforms.ToTensor()]) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PLEDataset(Dataset):\n",
    "    def __init__(self, data_list,shape,transform_pet,transform_mask):\n",
    "    # def __init__(self, img_paths, img_labels):\n",
    "        self.list = data_list\n",
    "        # self.labels = labels\n",
    "        self.shape = shape\n",
    "        # self.size_of_images = size_of_images\n",
    "        self.transform_mask = transform_mask\n",
    "        self.transform_pet = transform_pet\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list)\n",
    "    def __getitem__(self, index):\n",
    "        # img = cv2.resize(self.list[index],self.size_of_images)\n",
    "        path = self.list[index]\n",
    "        data = joblib.load(path)\n",
    "        pet = data[0]\n",
    "        mask = data[1]\n",
    "        num_layer = pet.shape[0]\n",
    "        # if num_layer>200:\n",
    "        if num_layer>387:\n",
    "\n",
    "            pet = pet[num_layer-387:num_layer-97,:,:]\n",
    "            mask = mask[num_layer-387:num_layer-97,:,:]\n",
    "        # shape = [134,100,100]\n",
    "        p1 = []\n",
    "        p2 = []\n",
    "        for i in range(3):\n",
    "            if pet.shape[i] < shape[i]:\n",
    "                a = int((shape[i]-pet.shape[i])/2)\n",
    "                p1.append(a)\n",
    "                p2.append(shape[i] - pet.shape[i] - a)\n",
    "            else:\n",
    "                p1.append(0)\n",
    "                p2.append(0)\n",
    "        img_pet = np.pad(pet,pad_width=((p1[0], p2[0]),\n",
    "                                        (p1[1], p2[1]),\n",
    "                                        (p1[2],p2[2])),mode=\"constant\",constant_values=(0,0))\n",
    "        img_mask = np.pad(mask,pad_width=((p1[0], p2[0]),\n",
    "                                        (p1[1], p2[1]),\n",
    "                                        (p1[2],p2[2])),mode=\"constant\",constant_values=(0,0))\n",
    "        c1 = abs(int((img_pet.shape[0]-shape[0])/2))\n",
    "        c2 = abs(int((img_pet.shape[0]+shape[0])/2))\n",
    "        h1 = abs(int((img_pet.shape[1]-shape[1])/2))\n",
    "        h2 = abs(int((img_pet.shape[1]+shape[1])/2))\n",
    "        w1 = abs(int((img_pet.shape[2]-shape[2])/2))\n",
    "        w2 = abs(int((img_pet.shape[2]+shape[2])/2))\n",
    "        img_pet = img_pet[c1:c2,h1:h2,w1:w2]\n",
    "        img_mask = img_mask[c1:c2,h1:h2,w1:w2]\n",
    "\n",
    "        img_pet = img_pet.astype(np.float32)\n",
    "        img_mask = img_mask.astype(np.float32)\n",
    "        TENSOR_pet = self.transform_pet(img_pet)\n",
    "        TENSOR_mask = self.transform_mask(img_mask)\n",
    "\n",
    "        return TENSOR_pet, TENSOR_mask\n",
    "shape = [256,256,256]\n",
    "train_path, test_path = train_test_split(path,test_size=0.2)\n",
    "train_set = PLEDataset(train_path,shape,transform_pet,transform_mask)\n",
    "test_set = PLEDataset(test_path,shape,transform_pet,transform_mask)\n",
    "train_loader = torch.utils.data.DataLoader(train_set,batch_size=4,shuffle=True,num_workers=2,pin_memory = False)\n",
    "test_loader = torch.utils.data.DataLoader(test_set,batch_size=4,shuffle=False,num_workers=2,pin_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import monai\n",
    "model = monai.networks.nets.UNet(spatial_dims=3, in_channels=1, out_channels=2,channels=(32,64,128,256),strides=(2,2,2)).to(device)\n",
    "# model = monai.networks.nets.BasicUNet().to(device)  # out of memory\n",
    "# model = monai.networks.nets.AttentionUnet(spatial_dims=3, in_channels=1, out_channels=2, channels=(32,64,128,256),strides=(2,2,2)).to(device)  # out of memory\n",
    "# model = monai.networks.nets.SwinUNETR(img_size=(128,128,128), in_channels=1, out_channels=2).to(device) # out of memory\n",
    "pretrain_path = './output/newspacing_400/weights/model389.pth'\n",
    "no_cuda = False\n",
    "gpu_id = [0]\n",
    "if not no_cuda:\n",
    "    if len(gpu_id) > 1:\n",
    "        model = model.cuda()\n",
    "        model = nn.DataParallel(model, device_ids=gpu_id)\n",
    "        net_dict = model.state_dict()\n",
    "    else:\n",
    "        import os\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(gpu_id[0])\n",
    "        model = model.cuda()\n",
    "        model = nn.DataParallel(model, device_ids=None)\n",
    "        net_dict = model.state_dict()\n",
    "else:\n",
    "    net_dict = model.state_dict()\n",
    "\n",
    "print('loading pretrained model {}'.format(pretrain_path))\n",
    "pretrain = torch.load(pretrain_path)\n",
    "# pretrain_dict = {k: v for k, v in pretrain['state_dict'].items() if k in net_dict.keys()}\n",
    "pretrain_dict = {k: v for k, v in pretrain.items() if k in net_dict.keys()}\n",
    "net_dict.update(pretrain_dict) \n",
    "model.load_state_dict(net_dict) \n",
    "\n",
    "print(\"-------- pre-train model load successfully --------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import logger, weights_init, metrics, common, loss\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "# criterion = torch.nn.BCELoss().to(device)\n",
    "criterion = loss.DiceLoss().to(device)\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.99)\n",
    "num_epochs = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "for epoch in range(num_epochs):\n",
    "    start = time.time()\n",
    "    per_epoch_loss = 0\n",
    "    score_list = [] \n",
    "    label_list = []\n",
    "    per_epoch_metrics = 0\n",
    "    \n",
    "    val_per_epoch_loss = 0\n",
    "    val_per_epoch_metrics = 0\n",
    "    \n",
    "    model.train()\n",
    "    with torch.enable_grad():\n",
    "        for x,label in tqdm(train_loader):\n",
    "            x = x.float()\n",
    "            x = x.to(device)\n",
    "            label = label.long()\n",
    "            label = common.to_one_hot_3d(label, 2)\n",
    "            label = label.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            x=torch.unsqueeze(x, dim=1)\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, label)\n",
    "            # print(loss)\n",
    "            per_epoch_loss += loss.item()\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # metrics = SegmentationMetric(2)\n",
    "            # pred = logits.detach().numpy()\n",
    "            # y = label.detach().numpy()\n",
    "            # pred, y = pred.astype(np.int32), y.astype(np.int32)\n",
    "            # hist = metrics.addBatch(pred, y)     \n",
    "            # mIoU = metrics.meanIntersectionOverUnion() \n",
    "            # jaccard = torchmetrics.JaccardIndex(task=\"multiclass\", num_classes=2)\n",
    "            # metrics = jaccard(logits, label)   \n",
    "            # metrics = monai.metrics.compute_iou(logits,label,include_background=False)[0]\n",
    "            score, not_nans = monai.metrics.DiceHelper(include_background=False, sigmoid=True, softmax=True)(logits,label)\n",
    "            per_epoch_metrics += score.item()\n",
    "            # print(loss,score,per_epoch_loss,not_nans)\n",
    "        #     pred = logits.argmax(dim=1)\n",
    "        #     num_correct += torch.eq(pred, label).sum().float().item()\n",
    "\n",
    "        # score_array = np.array(score_list)\n",
    "        # label_array = np.array(label_list)\n",
    "        # fpr_keras_1, tpr_keras_1, thresholds_keras_1 = roc_curve(label_array, score_array)\n",
    "        # auc_keras_1 = auc(fpr_keras_1,tpr_keras_1)        \n",
    "\n",
    "        print(\"Train Epoch: {}\\t Loss: {:.6f}\\t Acc: {}\\t\".format(epoch,per_epoch_loss/(2*len(train_loader)),2*per_epoch_metrics/len(train_loader.dataset)))\n",
    "        summaryWriter.add_scalars('loss', {\"loss\":(per_epoch_loss/(2*len(train_loader)))}, epoch)\n",
    "        summaryWriter.add_scalars('acc', {\"acc\":2*per_epoch_metrics/len(train_loader.dataset)}, epoch)\n",
    "\n",
    "        # summaryWriter.add_scalars('auc', {\"auc\":auc_keras_1}, epoch)\n",
    "      \n",
    "  \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x,label in tqdm(test_loader):\n",
    "            x = x.float() \n",
    "            x = x.to(device)\n",
    "            label = label.long()\n",
    "            label = common.to_one_hot_3d(label, 2)\n",
    "            label = label.to(device)\n",
    "            #label_n = label.cpu().numpy()\n",
    "            \n",
    "            # val_label_list.extend(label.cpu().numpy())\n",
    "            x=torch.unsqueeze(x, dim=1)\n",
    "           \n",
    "            # Forward pass\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, label)\n",
    "            # print(loss)\n",
    "            val_per_epoch_loss += loss.item()\n",
    "            # metrics = monai.metrics.compute_iou(logits,label,include_background=False)[0]\n",
    "            score, not_nans = monai.metrics.DiceHelper(include_background=False, sigmoid=True, softmax=True)(logits,label)\n",
    "            val_per_epoch_metrics += score.item()\n",
    "        print(\"val Epoch: {}\\t Loss: {:.6f}\\t Acc: {}\\t\".format(epoch,val_per_epoch_loss/(2*len(test_loader)),2*val_per_epoch_metrics/len(test_loader.dataset)))\n",
    "\n",
    "        summaryWriter.add_scalars('loss', {\"val_loss\":(val_per_epoch_loss/(2*len(test_loader)))}, epoch)\n",
    "\n",
    "        summaryWriter.add_scalars('acc', {\"val_acc\":2*val_per_epoch_metrics/len(test_loader.dataset)}, epoch)\n",
    "        summaryWriter.add_scalars('time', {\"time\":(time.time() - start)}, epoch)\n",
    "\n",
    "        \n",
    "    scheduler.step()\n",
    "    if (epoch+1) % 30 == 0:\n",
    "        filepath = \"./weights\"\n",
    "        folder = os.path.exists(filepath)\n",
    "        if not folder:\n",
    "            os.makedirs(filepath)\n",
    "        path = './weights/model' + str(epoch) + '.pth'\n",
    "        torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "92e3ab620c126cc1f5697f4e385fe3da6d2d5dfc7fafa874379b037d7a20cbdf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
